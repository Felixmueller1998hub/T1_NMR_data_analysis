{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79fdaca7-8653-4aa1-ac3b-9af56ad9e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bruker.api.topspin import Topspin\n",
    "from bruker.data.nmr  import *\n",
    "import pandas as pd\n",
    "import os as os\n",
    "import numpy as np\n",
    "import pprint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63daec16-ad6e-4a43-822c-fa26ac07e677",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "This example requires 1D dataset to be opened in TopSpin",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis example requires 1D dataset to be opened in TopSpin\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m     top\u001b[38;5;241m.\u001b[39mshowError(err)\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(err)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# apply some processing commands\u001b[39;00m\n\u001b[0;32m     12\u001b[0m curdat\u001b[38;5;241m.\u001b[39mlaunch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: This example requires 1D dataset to be opened in TopSpin"
     ]
    }
   ],
   "source": [
    "top = Topspin()\n",
    "dp = top.getDataProvider()\n",
    "# First, get the data set currently shown in TopSpin\n",
    "#\n",
    "curdat = top.getDataProvider().getCurrentDataset()\n",
    "if curdat is None or curdat.getDimension() > 1:\n",
    "    err = 'This example requires 1D dataset to be opened in TopSpin'\n",
    "    top.showError(err)\n",
    "    raise Exception(err)\n",
    "    \n",
    "# apply some processing commands\n",
    "curdat.launch('efp')\n",
    "\n",
    "info = curdat.getInfo()\n",
    "# print the keys of the dictionary first\n",
    "# dict_keys(['dataset_path', 'raw_data_dimension', 'proc_data_dimension', 'acquisition_date', 'acquisition_nuclei', 'spectrometer_frequency', 'solvent', 'pulse_program', 'spec_typ', 'title'])\n",
    "# pretty print of dictionary\n",
    "pprint.pprint(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1d51739-269e-4b74-9cad-c9f9bdcd9f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 393.4158020019531, 'end': -463.89411974545703, 'unit': 'ppm', 'referenceFrequency': 0.0}\n",
      "{'firstPoint': 0, 'numberOfPoints': 16384}\n"
     ]
    }
   ],
   "source": [
    "#RUN THIS CELL FOR ONEPULSE spectrum\n",
    "#read the whole processed spectrum into dictionary\n",
    "#dict_keys(['indexRanges', 'physicalRanges', 'dataPoints'])\n",
    "\n",
    "title = '18.1nofiller-60C'\n",
    "\n",
    "output_file_path = rf'C:\\Users\\felix\\NMRdeconvoluted_txt\\18.1nofiller\\{title}.txt'\n",
    "#################set title############################\n",
    "\n",
    "curdat = top.getDataProvider().getCurrentDataset()\n",
    "specData = curdat.getSpecDataPoints()\n",
    "\n",
    "curdat.launch('abs')\n",
    "\n",
    "if specData.get(EXCEPTION):\n",
    "    print('Error :',specData.get(EXCEPTION).details())\n",
    "    exit(-1)\n",
    "\n",
    "# gives me my ranges\n",
    "ir = specData['indexRanges'][0]\n",
    "pr = specData['physicalRanges'][0]\n",
    "print(pr)\n",
    "print(ir)\n",
    "\n",
    "start_point = pr.getStart()\n",
    "end_point = pr.getEnd()\n",
    "num_points = ir.getNum()\n",
    "\n",
    "#convert spectral data to a format that decon3.0 can use\n",
    "recovered = specData['dataPoints']\n",
    "\n",
    "#impletement startpoint and endpoint into heading of the textfile before saving\n",
    "heading = f\"Start Point: {start_point}\\nEnd Point: {end_point}\\n\"\n",
    "\n",
    "# Save the data points to a text file with heading\n",
    "np.savetxt(output_file_path, recovered, header=heading)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65af3ca6-26c1-46c3-abbf-dc3774ccf118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T=55C (328K)\n",
      "7Li Minion static\n",
      "Sample = PEO with LiTFSI 18-1 (no filler)\n",
      "in sec\n",
      "0.0001\n",
      "0.0002\n",
      "0.0005\n",
      "0.001\n",
      "0.002\n",
      "0.005\n",
      "0.01\n",
      "0.02\n",
      "0.03\n",
      "0.05\n",
      "0.1\n",
      "0.15\n",
      "0.2\n",
      "0.3\n",
      "0.5\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "10\n",
      "{'start': 502.9158935546875, 'end': -499.7857693077858, 'unit': 'ppm', 'referenceFrequency': 0.0}\n",
      "{'firstPoint': 0, 'numberOfPoints': 32768}\n",
      "Folder created at C:\\Users\\felix\\NMRdeconvoluted_txt\\18.1nofiller\\18.1nofiller55C\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS CELL FOR For satrec1nodec T1\n",
    "# Open the satrec1nodec file in Bruker and adjust phase manually\n",
    "def create_folder(filepath):\n",
    "    try:\n",
    "        # Use os.makedirs() to create the folder and any necessary parent folders\n",
    "        os.makedirs(filepath)\n",
    "        print(f\"Folder created at {filepath}\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Folder already exists at {filepath}\")\n",
    "\n",
    "#################################################################set title################################################################\n",
    "\n",
    "foldertitle= '18.1nofiller60C'\n",
    "\n",
    "firstfolder= '18.1nofiller'\n",
    "    \n",
    "#get current data shown\n",
    "curdat = top.getDataProvider().getCurrentDataset()\n",
    "specData = curdat.getSpecDataPoints()\n",
    "\n",
    "#baseline correction\n",
    "curdat.launch('abs')\n",
    "#show title to make sure its the right dataset\n",
    "info = curdat.getInfo()\n",
    "print(info['title'])\n",
    "\n",
    "if specData.get(EXCEPTION):\n",
    "    print('Error :',specData.get(EXCEPTION).details())\n",
    "    exit(-1)\n",
    "\n",
    "# gives me my ranges\n",
    "ir = specData['indexRanges'][0]\n",
    "pr = specData['physicalRanges'][0]\n",
    "print(pr)\n",
    "print(ir)\n",
    "\n",
    "start_point = pr.getStart()\n",
    "end_point = pr.getEnd()\n",
    "num_points = ir.getNum()\n",
    "\n",
    "#convert spectral data to a format that decon3.0 can use\n",
    "recovered = specData['dataPoints']\n",
    "\n",
    "#Make folder\n",
    "folder_path = rf'C:\\Users\\felix\\NMRdeconvoluted_txt\\{firstfolder}\\{foldertitle}'\n",
    "create_folder(folder_path)\n",
    "\n",
    "#for loop that goes through the vdlist and makes a text file for each measurement\n",
    "for i in range(20):\n",
    "    #write the big file into multiple small ones define slicing index\n",
    "    str_index = i*num_points\n",
    "    end_index = (i+1)*num_points\n",
    "    #get the i-th num_points from recovered array slicing the array\n",
    "    snippet = recovered[str_index:end_index:1]\n",
    "    #impletement startpoint and endpoint into heading of the textfile before saving\n",
    "    heading = f\"Start Point: {start_point}\\nEnd Point: {end_point}\\n\"\n",
    "\n",
    "    #save it in a text\n",
    "    output_file_path = rf'C:\\Users\\felix\\NMRdeconvoluted_txt\\{firstfolder}\\{foldertitle}\\{i+1}.txt'\n",
    "    np.savetxt(output_file_path, snippet, header=heading)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b1b955-bb21-421e-aec5-ee5915402a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
